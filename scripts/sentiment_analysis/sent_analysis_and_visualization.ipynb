{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "## sentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "## LDA\n",
    "from gensim import corpora\n",
    "import gensim\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "#import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18bdb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "df_2022 = pd.read_csv('../output/2022_sentiment.csv')\n",
    "df_2018 = pd.read_csv('../output/2018_sentiment.csv')\n",
    "df_2020 = pd.read_csv('../output/2020_sentiment.csv')\n",
    "\n",
    "nat_disas = pd.read_csv(\"../data/disasters.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_disas[\"year\"] = nat_disas[\"start_date\"].str[:4]\n",
    "nat_disas_2018 = (nat_disas[nat_disas[\"year\"] == \"2018\"])\n",
    "nat_disas_2020 = (nat_disas[nat_disas[\"year\"] == \"2020\"])\n",
    "\n",
    "num_nat_disas_2018 = nat_disas_2018.shape[0]\n",
    "num_nat_disas_2018\n",
    "num_nat_disas_2020 = nat_disas_2020.shape[0]\n",
    "num_nat_disas_2020\n",
    "\n",
    "avg_compound_2018 = df_2018.loc[:, \"compound_scores\"].mean()\n",
    "avg_compound_2020 = df_2020.loc[:, \"compound_scores\"].mean()\n",
    "\n",
    "\n",
    "plt.bar([\"2018\", \"2020\"], [num_nat_disas_2018, num_nat_disas_2020], color = \"teal\")\n",
    "plt.ylabel(\"Number of Natural Disasters\")\n",
    "plt.title(\"Number of Natural Disasters Globally by Year\")\n",
    "plt.show()\n",
    "\n",
    "#barwidth = 0.5\n",
    "#br1 = np.arange(len([\"2018\", \"2020\"]))\n",
    "#br2 = [x + barwidth for x in br1]\n",
    "\n",
    "#fig, ax1 = plt.subplots()\n",
    "#color = 'tab:red'\n",
    "#ax1.set_ylabel('Number of Natural Disasters', color=color)\n",
    "#ax1.bar([\"2018\", \"2020\"], [num_nat_disas_2018, num_nat_disas_2020], color=color, position = 0)\n",
    "#ax1.tick_params(axis='y', labelcolor=color)\n",
    "#ax2 = ax1.twinx()  # instantiate a second Axes that shares the same x-axis\n",
    "\n",
    "#color = 'tab:blue'\n",
    "#ax2.set_ylabel('Average Sentiment Score', color=color)  # we already handled the x-label with ax1\n",
    "#ax2.bar([\"2018\", \"2020\"], [avg_compound_2018, avg_compound_2020], color=color, position = 1)\n",
    "#ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "#fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.show()\n",
    "\n",
    "plt.bar([\"2018\", \"2020\"], [avg_compound_2018, avg_compound_2020], color = \"teal\")\n",
    "plt.ylabel(\"Average Compound Sentiment Score\")\n",
    "plt.title(\"Average Sentiment Score by Year\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e634d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be10f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = SnowballStemmer(\"english\")\n",
    "custom_stopwords = [\"climate\", \"change\", \"warm\", \"https\", \"global\", \"will\", \"this\", \"that\", \"what\",\n",
    "                    \"cause\", \"from\", \"like\", \"have\", \"they\", \"climatechange\", \"with\", \"about\", \"more\",\n",
    "                    \"replied\", \"tweet\", \"reply\"]\n",
    "## your code defining a text processing function\n",
    "def processing(text_ex):\n",
    "    tokens = word_tokenize(text_ex.lower()) # lowercase\n",
    "    filtered_tokens = [word for word in tokens if word not in custom_stopwords]\n",
    "    example_listing_preprocess = [porter.stem(token)\n",
    "                                for token in filtered_tokens\n",
    "                                if token.isalpha() and\n",
    "                                len(token) >= 4]\n",
    "\n",
    "    final_list = [\" \".join(example_listing_preprocess)]\n",
    "    return final_list\n",
    "\n",
    "df_2018[\"processed_text\"] = [processing(text) for text in df_2018[\"Embedded_text\"]]\n",
    "df_2022[\"processed_text\"] = [processing(text) for text in df_2022[\"Embedded_text\"]]\n",
    "df_2020[\"processed_text\"] = [processing(text) for text in df_2020[\"Embedded_text\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55631d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR 2018\n",
    "tokenized_docs = [doc[0].split() for doc in df_2018[\"processed_text\"]]\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_docs]\n",
    "\n",
    "lda = lda_model = gensim.models.LdaModel(\n",
    "    corpus = corpus,\n",
    "    id2word = dictionary,\n",
    "    num_topics = 4,\n",
    "    random_state = 122,\n",
    ")\n",
    "\n",
    "lda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=custom_stopwords,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show() ## 2018 PLOT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR 2020\n",
    "tokenized_docs = [doc[0].split() for doc in df_2020[\"processed_text\"]]\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_docs]\n",
    "\n",
    "lda = lda_model = gensim.models.LdaModel(\n",
    "    corpus = corpus,\n",
    "    id2word = dictionary,\n",
    "    num_topics = 4,\n",
    "    random_state = 122,\n",
    ")\n",
    "\n",
    "lda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=custom_stopwords,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show() ## 2020 PLOT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR 2022\n",
    "tokenized_docs = [doc[0].split() for doc in df_2022[\"processed_text\"]]\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_docs]\n",
    "\n",
    "lda = lda_model = gensim.models.LdaModel(\n",
    "    corpus = corpus,\n",
    "    id2word = dictionary,\n",
    "    num_topics = 4,\n",
    "    random_state = 122,\n",
    ")\n",
    "\n",
    "lda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e363efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=custom_stopwords,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show() ## 2022 PLOT!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570c6624",
   "metadata": {},
   "source": [
    "Citations:\n",
    "1. https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/#9.-Word-Clouds-of-Top-N-Keywords-in-Each-Topic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qss20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
